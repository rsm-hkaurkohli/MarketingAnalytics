{"title":"1 DATA","markdown":{"yaml":{"title":"1 DATA"},"headingText":"Read Data","containsRefs":false,"markdown":"\n\n\n\n\n\n\n\n### Compare histograms and means of number of patents by customer status. What do you observe?\n\n### Compare regions and ages by customer status. What do you observe?\n\n## 2. Estimation of Simple Poisson Model\n\n### Write down mathematically the likelihood for $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n![image.png](attachment:image.png)\n\n###  Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n```\npoisson_loglikelihood <- function(lambda, Y){\n   ...\n}\n```\n\n\n### Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._\n\n## If you're feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which \"feels right\" because the mean of a Poisson distribution is lambda._\n\n\n![image.png](attachment:image.png)\n\n![image.png](attachment:image.png)\n\n![image.png](attachment:image.png)\n\n### Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n## 3. Estimation of Poisson Regression Model\n\n### Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ $\\lambda_i = e^{X_i'\\beta}$. _For example:\n\n```\npoisson_regression_likelihood <- function(beta, Y, X){\n   ...\n}\n```\n\n### Use your function along with R's optim() or Python's sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1's to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n\n###  Check your results using R's glm() function or Python sm.GLM() function.\n\n###  Interpret the results.\n\nInterpretation of Poisson Regression Results\nThe Poisson regression model estimates the number of patents awarded to engineering firms as a function of several covariates, including firm age, age squared, regional location, and whether the firm is a customer of Blueprinty. The key findings are as follows:\n\nBlueprinty Customer Status:\nThe coefficient for the iscustomer variable is 0.208 and statistically significant at the 1% level (p < 0.001). This implies that, holding all other variables constant, firms using Blueprinty's software experience a higher expected count of patents. Exponentiating the coefficient yields an incidence rate ratio of \nexp\n⁡\n(\n0.208\n)\n≈\n1.23\nexp(0.208)≈1.23, indicating that customers of Blueprinty are expected to receive approximately 23% more patents over the five-year period than non-customers. This provides empirical support for Blueprinty's marketing claim.\n\nFirm Age and Age Squared:\nThe model includes both age and age squared to capture non-linear effects. The coefficient on age is 0.149 (p < 0.001), suggesting that the number of patents increases with firm age. However, the coefficient on age squared is -0.003 (p < 0.001), indicating diminishing returns to age. Together, these results imply an inverted U-shaped relationship: patent success rates rise with firm age initially but taper off or decline for very mature firms.\n\nRegional Effects:\nDummy variables for regional location were included, with one region omitted as the reference group. None of the regional coefficients were statistically significant at conventional levels (p > 0.05), suggesting that regional location does not materially influence patent counts once age and software usage are controlled for.\n\nConclusion\nThe results of the Poisson regression model provide strong evidence that Blueprinty's software is positively associated with a higher rate of patent awards. Firm age is also a significant predictor, though its effect diminishes at higher levels. The analysis finds no compelling evidence that regional variation plays a significant role. These findings support the use of Blueprinty's product among engineering firms seeking to enhance their patent success rates.\n\n\n\n### What do you conclude about the effect of Blueprinty's software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences.\n\n# AirBnB Case Study\n\n## # Drop rows with missing values in relevant variables\nrelevant_vars = [\n    'number_of_reviews', 'days', 'room_type', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value', 'instant_bookable'\n]\nairbnb_clean = airbnb_df[relevant_vars].dropna()\n\n# Confirm the shape after dropping missing values\nprint(f\"Original size: {airbnb_df.shape}, After cleaning: {airbnb_clean.shape}\")\n\n\n### data cleaning and prep\n\n### EDA\n\n### Feature Modelling\n\n### REGRESSION \n\n### INTERRETATION OF RESULTS\n\n## A Poisson regression model was used to analyze how Airbnb listing characteristics affect the number of reviews, which serve as a proxy for bookings. The results indicate that listings active on the platform for longer periods accumulate more reviews, with each additional day contributing a small but statistically significant increase. Higher nightly prices are also positively associated with review counts, although the effect size is modest.\n\n## Listings with more bedrooms receive substantially more reviews—each additional bedroom is linked to a 12.7% increase in expected bookings. Importantly, room type significantly affects performance: private rooms receive approximately 55% fewer reviews than entire homes or apartments, suggesting a strong guest preference for full-property rentals.\n\n## Furthermore, listings with the “instant book” feature perform better, averaging 22% more reviews than those requiring manual approval. This highlights the benefit of reducing booking friction for potential guests.\n\n## Overall, the analysis suggests that to increase bookings, hosts may benefit from offering entire properties, enabling instant booking, and enhancing their listings over time. These findings can help guide pricing and feature decisions to improve listing visibility and appeal.\n","srcMarkdownNoYaml":"\n\n\n\n\n\n\n### Read Data\n\n### Compare histograms and means of number of patents by customer status. What do you observe?\n\n### Compare regions and ages by customer status. What do you observe?\n\n## 2. Estimation of Simple Poisson Model\n\n### Write down mathematically the likelihood for $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n![image.png](attachment:image.png)\n\n###  Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n```\npoisson_loglikelihood <- function(lambda, Y){\n   ...\n}\n```\n\n\n### Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._\n\n## If you're feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which \"feels right\" because the mean of a Poisson distribution is lambda._\n\n\n![image.png](attachment:image.png)\n\n![image.png](attachment:image.png)\n\n![image.png](attachment:image.png)\n\n### Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n## 3. Estimation of Poisson Regression Model\n\n### Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ $\\lambda_i = e^{X_i'\\beta}$. _For example:\n\n```\npoisson_regression_likelihood <- function(beta, Y, X){\n   ...\n}\n```\n\n### Use your function along with R's optim() or Python's sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1's to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n\n###  Check your results using R's glm() function or Python sm.GLM() function.\n\n###  Interpret the results.\n\nInterpretation of Poisson Regression Results\nThe Poisson regression model estimates the number of patents awarded to engineering firms as a function of several covariates, including firm age, age squared, regional location, and whether the firm is a customer of Blueprinty. The key findings are as follows:\n\nBlueprinty Customer Status:\nThe coefficient for the iscustomer variable is 0.208 and statistically significant at the 1% level (p < 0.001). This implies that, holding all other variables constant, firms using Blueprinty's software experience a higher expected count of patents. Exponentiating the coefficient yields an incidence rate ratio of \nexp\n⁡\n(\n0.208\n)\n≈\n1.23\nexp(0.208)≈1.23, indicating that customers of Blueprinty are expected to receive approximately 23% more patents over the five-year period than non-customers. This provides empirical support for Blueprinty's marketing claim.\n\nFirm Age and Age Squared:\nThe model includes both age and age squared to capture non-linear effects. The coefficient on age is 0.149 (p < 0.001), suggesting that the number of patents increases with firm age. However, the coefficient on age squared is -0.003 (p < 0.001), indicating diminishing returns to age. Together, these results imply an inverted U-shaped relationship: patent success rates rise with firm age initially but taper off or decline for very mature firms.\n\nRegional Effects:\nDummy variables for regional location were included, with one region omitted as the reference group. None of the regional coefficients were statistically significant at conventional levels (p > 0.05), suggesting that regional location does not materially influence patent counts once age and software usage are controlled for.\n\nConclusion\nThe results of the Poisson regression model provide strong evidence that Blueprinty's software is positively associated with a higher rate of patent awards. Firm age is also a significant predictor, though its effect diminishes at higher levels. The analysis finds no compelling evidence that regional variation plays a significant role. These findings support the use of Blueprinty's product among engineering firms seeking to enhance their patent success rates.\n\n\n\n### What do you conclude about the effect of Blueprinty's software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences.\n\n# AirBnB Case Study\n\n## # Drop rows with missing values in relevant variables\nrelevant_vars = [\n    'number_of_reviews', 'days', 'room_type', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value', 'instant_bookable'\n]\nairbnb_clean = airbnb_df[relevant_vars].dropna()\n\n# Confirm the shape after dropping missing values\nprint(f\"Original size: {airbnb_df.shape}, After cleaning: {airbnb_clean.shape}\")\n\n\n### data cleaning and prep\n\n### EDA\n\n### Feature Modelling\n\n### REGRESSION \n\n### INTERRETATION OF RESULTS\n\n## A Poisson regression model was used to analyze how Airbnb listing characteristics affect the number of reviews, which serve as a proxy for bookings. The results indicate that listings active on the platform for longer periods accumulate more reviews, with each additional day contributing a small but statistically significant increase. Higher nightly prices are also positively associated with review counts, although the effect size is modest.\n\n## Listings with more bedrooms receive substantially more reviews—each additional bedroom is linked to a 12.7% increase in expected bookings. Importantly, room type significantly affects performance: private rooms receive approximately 55% fewer reviews than entire homes or apartments, suggesting a strong guest preference for full-property rentals.\n\n## Furthermore, listings with the “instant book” feature perform better, averaging 22% more reviews than those requiring manual approval. This highlights the benefit of reducing booking friction for potential guests.\n\n## Overall, the analysis suggests that to increase bookings, hosts may benefit from offering entire properties, enabling instant booking, and enhancing their listings over time. These findings can help guide pricing and feature decisions to improve listing visibility and appeal.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"MAA2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.5","theme":["cosmo","brands"],"title":"1 DATA"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}